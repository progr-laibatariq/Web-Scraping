{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T18:00:20.916756Z",
     "start_time": "2026-01-19T18:00:19.095711Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_product(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Note: Selectors vary by site. These are generic placeholders.\n",
    "            title = soup.find('h1').get_text(strip=True) if soup.find('h1') else \"N/A\"\n",
    "            price = soup.find('span', class_='price').get_text(strip=True) if soup.find('span', class_='price') else \"N/A\"\n",
    "\n",
    "            data = {\n",
    "                \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"Product Name\": title,\n",
    "                \"Price\": price,\n",
    "                \"Source URL\": url\n",
    "            }\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of URLs to track\n",
    "urls = [\"https://www.limelight.pk/collections/embroidered-pret\"]\n",
    "results = [scrape_product(u) for u in urls if scrape_product(u)]\n",
    "\n",
    "# Save to Excel\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"price_tracking_results.xlsx\", index=False)\n",
    "print(\"Data saved to price_tracking_results.xlsx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to price_tracking_results.xlsx\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T18:06:17.307247Z",
     "start_time": "2026-01-19T18:06:15.672229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_product(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # 1. Capture the Product Name\n",
    "            title = soup.find('h1').get_text(strip=True) if soup.find('h1') else \"N/A\"\n",
    "\n",
    "            # 2. Capture the Price using the 'money' class from your inspect tool\n",
    "            # We look for the span with class 'money' inside the price container\n",
    "            price_elem = soup.select_one(\"span.price-item--regular span.money\")\n",
    "\n",
    "            # If it's a sale item, the class might change, so we add a fallback\n",
    "            if not price_elem:\n",
    "                price_elem = soup.select_one(\"span.price-item--sale span.money\")\n",
    "\n",
    "            price = price_elem.get_text(strip=True) if price_elem else \"N/A\"\n",
    "\n",
    "            return {\n",
    "                \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"Product Name\": title,\n",
    "                \"Price\": price,\n",
    "                \"Source URL\": url\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Your existing logic to run and save to Excel follows...\n",
    "# List of URLs to track\n",
    "urls = [\"https://www.limelight.pk/collections/embroidered-pret\"]\n",
    "results = [scrape_product(u) for u in urls if scrape_product(u)]\n",
    "\n",
    "# Save to Excel\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"tracking_results.xlsx\", index=False)\n",
    "print(\"Data saved to tracking_results.xlsx\")"
   ],
   "id": "e5fc62daf98192bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tracking_results.xlsx\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T18:08:33.570294Z",
     "start_time": "2026-01-19T18:08:32.185275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def scrape_limelight_page(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    product_list = []\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Step 1: Find all product cards (containers)\n",
    "            # On Limelight, each product is usually in a 'div' or 'li' with a specific class\n",
    "            products = soup.find_all('div', class_='product-card-wrapper')\n",
    "\n",
    "            for product in products:\n",
    "                # Step 2: Extract details for EACH product in the loop\n",
    "                # Adjust these selectors based on your specific inspect tool findings\n",
    "                name_elem = product.find('a', class_='full-unstyled-link')\n",
    "                price_elem = product.select_one(\"span.price-item--regular span.money\")\n",
    "\n",
    "                if not price_elem:\n",
    "                    price_elem = product.select_one(\"span.price-item--sale span.money\")\n",
    "\n",
    "                product_list.append({\n",
    "                    \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"Product Name\": name_elem.get_text(strip=True) if name_elem else \"N/A\",\n",
    "                    \"Price\": price_elem.get_text(strip=True) if price_elem else \"N/A\",\n",
    "                    \"Source URL\": url\n",
    "                })\n",
    "\n",
    "            return product_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run the scraper\n",
    "target_url = \"https://www.limelight.pk/collections/embroidered-pret\"\n",
    "all_products = scrape_limelight_page(target_url)\n",
    "\n",
    "# Save all results to Excel\n",
    "if all_products:\n",
    "    df = pd.DataFrame(all_products)\n",
    "    df.to_excel(\"limelight_products.xlsx\", index=False)\n",
    "    print(f\"Success! Saved {len(all_products)} products to Excel.\")"
   ],
   "id": "58b1b8567a968b37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved 24 products to Excel.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ad9eacff344b814"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
